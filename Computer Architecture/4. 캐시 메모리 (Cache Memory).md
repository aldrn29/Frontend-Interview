## 캐시 메모리 (Cache Memory)

#### 캐시 
자주 사용하는 데이터나 값을 미리 복사해 놓는 임시 장소이다.

#### 캐시 메모리
- 속도가 빠른 장치와 느린 장치에서 속도 차이에 따른 병목 현상을 줄이기 위한 메모리를 말한다. 
- CPU와 메모리 사이의 속도 차이를 줄이기 위한 고속 메모리이다. CPU가 주기억장치에서 저장된 데이터를 읽어올 때, 자주 사용하는 데이터를 캐시 메모리에 저장한 뒤, 다음에 이용할 때 주기억장치가 아닌 캐시 메모리에서 먼저 가져오면서 속도를 향상시킨다.
- CPU에는 이러한 캐시 메모리가 2~3개 정도 사용된다. (L1, L2, L3 캐시 메모리) 속도와 크기에 따라 분류한 것으로, 일반적으로 L1 캐시부터 먼저 사용된다. (CPU에서 가장 빠르게 접근하고, 데이터를 찾지 못하면 L2)

```
L1 : CPU 내부에 존재
L2 : CPU와 RAM 사이에 존재
L3 : 보통 메인보드에 존재한다고 함
```

#### 듀얼 코어 프로세서의 캐시 메모리
각 코어마다 독립된 L1 캐시 메모리를 가지고, 두 코어가 공유하는 L2 캐시 메모리가 내장됨

#### 디스크 캐시
주기억장치(RAM)와 보조기억장치(하드디스크) 사이에 존재하는 캐시

<br><br>  
## 캐시의 특징
- 속도가 빠른 장치와 느린 장치에서 속도 차이에 따른 병목 현상을 줄여준다. (속도 향상)
- 높은 비용으로 인해 작은 용량으로 구성되며, 컴퓨터 성능에 영향을 준다. (캐시 메모리 크기가 작은 이유는, SRAM 가격이 매우 비싸기 때문)
- 프로그래머는 캐시 메모리를 조작할 수 있는 명령어가 없다. (투명성)
 
<br><br>  
## 캐시의 기본 동작

<p align="center">
  <img src="https://github.com/aldrn29/Frontend-Interview/blob/main/Resources/캐시의 기본 동작.png?raw=true" width="25%">
</p>

1. CPU가 데이터 필요시, 원하는 데이터 주소를 캐시로 보낸다. (태그 메모리를 탐색, 비교)
2. Cache Hit : 태그 일치(Hit) 시, 캐시의 해당 블록에 접근하고 원하는 워드를 CPU로 전송한다. 필요시, 블록 갱신방식에 따라 참조된 블록 갱신 비트를 사용하여 블록 수정 여부 표시한다.
3. Cache Miss : 태그 불일치(Miss) 시, 캐시는 실패 시그널을 CPU에 보내고, CPU는 메모리에서 원하는 블록을 가져와 캐시의 데이터 메모리에 복사한다. (대응하는 태그를 갱신하고, 원하는 워드를 사용)
 
#### 참조 지역성
캐시에 데이터를 저장할 때는 참조 지역성의 원리가 존재한다.
- 시간 지역성 : for, while 같은 반복문에 사용하는 조건 변수처럼, 한번 참조된 데이터는 잠시후 또 참조될 가능성이 높다.
- 공간 지역성 : A[0], A[1]과 같은 연속 접근 시, 참조된 데이터 근처에 있는 데이터가 잠시후 또 사용될 가능성이 높다.

이러한 참조 지역성(공간)을 최대한 활용하기 위해 해당 데이터뿐만 아니라, 옆 주소의 데이터도 같이 가져와 미래에 쓰일 것을 대비한다. 즉, CPU가 요청한 데이터가 캐시에 있으면 **Cache Hit**, 없어서 DRAM에서 가져오면 **Cache Miss**인 것이다.

#### 캐시 미스(Cache Miss)의 경우 3가지
- Cold miss : 해당 메모리 주소를 처음 불러서 나는 미스
- Conflict miss : 캐시 메모리에 A와 B 데이터를 저장해야 하는데, A와 B가 같은 캐시 메모리 주소에 할당되어 있어서 나는 미스 (direct mapped cache에서 많이 발생)
- Capacity miss : 캐시 메모리의 공간이 부족해서 나는 미스 (Conflict는 주소 할당 문제, Capacity는 공간 문제), 캐시 크기를 키워서 문제를 해결하려하면, 캐시 접근속도가 느려지고 파워를 많이 먹는 단점이 생김

<br><br>  
## 캐시에 필요한 전략과 설계 논점
- **블록 사상(mapping) 방식** : 캐시 블록과 메모리 블록을 대응시키는 방식
- 블록 교체(replacement) 방식 : 캐시 miss로 새 블록을 갖고 왔는데 캐시 내 빈 곳이 없을 때, 캐시 내 블록 중 어떤 것을 선택, 교체할지를 결정하는 방식 (무작위(random), 선입 선출(FIFO), 최소 최근 사용(LRU))
- 블록 갱신(writing) 방식 : 캐시 내 데이터가 수정되었을 때, 대응하는 메모리의 데이터에 대한 갱신 시점을 결정하는 방식 (즉시 쓰기, 나중 쓰기)
 
#### 블록 사상 방식
캐시는 메모리보다 용량이 작기 때문에, 다수의 메모리 블록이 동일한 캐시 블록에 사상(how to place a memory block into Cache)한다.

> 1. 직접 사상 (direct mapping) : 메모리 블록을 정해진 하나의 캐시 블록에만 사상
> 2. 완전 연관 사상 (fully-associative mapping) : 메모리 블록을 어떤 캐시 블록에도 사상
> 3. 집합 연관 사상 (set-associative mapping) : 직접 사상과 완전 연관 사상을 절충하여, 메모리 블록을 정해진 블록의 집합 내 어디든 사상

1. Direct Mapped Cache  
가장 기본적인 구조로, DRAM의 여러 주소가 캐시 메모리의 한 주소에 대응되는 다대일 방식이다. 

2. Fully Associative Cache  
비어있는 캐시 메모리가 있으면, 마음대로 주소를 저장하는 방식이다.
저장할 때는 매우 간단하지만, 찾을 때 조건이나 규칙이 없어서 특정 캐시 Set 안에 있는 모든 블럭을 한번에 찾아 원하는 데이터가 있는지 검색해야 하는 문제가 있다. CAM이라는 특수한 메모리 구조를 사용해야하지만 가격이 매우 비싸다.

3. Set Associative Cache  
Direct + Fully으로 특정 행을 지정하고, 그 행안의 어떤 열이든 비어있을 때 저장하는 방식이다. Direct에 비해 검색 속도는 느리지만, 저장이 빠르고 Fully에 비해 저장이 느린 대신 검색이 빠른 중간형이다. 위 두가지보다 나중에 나온 방식이다.